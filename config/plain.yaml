optimizer:
    lr: 2.5e-4
    eps: 1e-5
    clip_grad: .5

embedding:
    size: 1
    history_size: 1
    hidden_size: 1
    epochs: 0
    pretrain: 2 # = off embedding

agent:
    pi_clip: .1
    gamma: .99
    epochs: 3
    batch_size: 256
    ent_k: .01
    val_loss_k: 1
    gae_lambda: .95

train:
    steps: 9766 # 10M / (128 * 8)
    rollout_size: 128
    num_env: 8
    log_every: 1
